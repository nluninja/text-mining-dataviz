{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDWwBdf_WYym"
      },
      "source": [
        "___\n",
        "\n",
        "TEXT MINING - NEURAL NETWORKS\n",
        "___\n",
        "\n",
        "# Simple Classifier with Keras\n",
        "\n",
        "Welcome to the section on deep learning! We'll be using Keras with a TensorFlow backend to perform our deep learning operations.\n",
        "\n",
        "This means we should get familiar with some Keras fundamentals and basics!\n",
        "\n",
        "## Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mqzdfnWjWYyn"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iru5aa7EWYyo"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We will use the famous Iris Data set.\n",
        "_____\n",
        "More info on the data set:\n",
        "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
        "\n",
        "## Reading in the Data Set\n",
        "\n",
        "We've already downloaded the dataset, its in this folder. So let's open it up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g0IFTQskWYyo"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "edh5Vkr2WYyo"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FteY9F5hWYyo",
        "outputId": "7f4166d7-492f-446b-8d55-a53286464555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.utils._bunch.Bunch</b><br/>def __init__(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sklearn/utils/_bunch.py</a>Container object exposing keys as attributes.\n",
              "\n",
              "Bunch objects are sometimes used as an output for functions and methods.\n",
              "They extend dictionaries by enabling values to be accessed by key,\n",
              "`bunch[&quot;value_key&quot;]`, or by an attribute, `bunch.value_key`.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from sklearn.utils import Bunch\n",
              "&gt;&gt;&gt; b = Bunch(a=1, b=2)\n",
              "&gt;&gt;&gt; b[&#x27;b&#x27;]\n",
              "2\n",
              "&gt;&gt;&gt; b.b\n",
              "2\n",
              "&gt;&gt;&gt; b.a = 3\n",
              "&gt;&gt;&gt; b[&#x27;a&#x27;]\n",
              "3\n",
              "&gt;&gt;&gt; b.c = 6\n",
              "&gt;&gt;&gt; b[&#x27;c&#x27;]\n",
              "6</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 4);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "type(iris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S--5OgP6WYyo",
        "outputId": "c2621af1-3837-41b1-e1e7-313d9ac641d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 150 (50 in each of three classes)\n",
            ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
            ":Attribute Information:\n",
            "    - sepal length in cm\n",
            "    - sepal width in cm\n",
            "    - petal length in cm\n",
            "    - petal width in cm\n",
            "    - class:\n",
            "            - Iris-Setosa\n",
            "            - Iris-Versicolour\n",
            "            - Iris-Virginica\n",
            "\n",
            ":Summary Statistics:\n",
            "\n",
            "============== ==== ==== ======= ===== ====================\n",
            "                Min  Max   Mean    SD   Class Correlation\n",
            "============== ==== ==== ======= ===== ====================\n",
            "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "============== ==== ==== ======= ===== ====================\n",
            "\n",
            ":Missing Attribute Values: None\n",
            ":Class Distribution: 33.3% for each of 3 classes.\n",
            ":Creator: R.A. Fisher\n",
            ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            ":Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. dropdown:: References\n",
            "\n",
            "  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "    Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "    Structure and Classification Rule for Recognition in Partially Exposed\n",
            "    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "    on Information Theory, May 1972, 431-433.\n",
            "  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "    conceptual clustering system finds 3 classes in the data.\n",
            "  - Many, many more ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(iris.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oc67wPo3WYyp"
      },
      "outputs": [],
      "source": [
        "X = iris.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VGY4BhTqWYyp",
        "outputId": "f4ef437f-0bb8-407f-b713-4d52e0d996d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A-zJNfDOWYyp"
      },
      "outputs": [],
      "source": [
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xT0sGQGIWYyp",
        "outputId": "0a0cb56b-c9e7-47c2-e51a-7919d9c7c366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "id": "_oyEKxSzWYyp"
      },
      "outputs": [],
      "source": [
        "#before tf 2.6\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "#since tf 2.6 and later\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rlU50xZpWYyp"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hn5KOBydWYyp",
        "outputId": "cc0eeb5e-28c4-43ab-ffa6-0f47ca2960cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x5Q5Vh6GWYyp",
        "outputId": "9d66884a-5961-45ec-f318-e91fa06da08f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SGvc3Y1WYyq"
      },
      "source": [
        "## Split the Data into Training and Test\n",
        "\n",
        "Its time to split the data into a train/test set. Keep in mind, sometimes people like to split 3 ways, train/test/validation. We'll keep things simple for now. **Remember to check out the video explanation as to why we split and what all the parameters mean!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YtTWjcxCWYyq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z3Qw2QzhWYyq"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "id": "honiouEcWYyq",
        "outputId": "099e1ab9-f4d2-49f7-cdb9-96c29fa8690f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7, 2.9, 4.2, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [7.1, 3. , 5.9, 2.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6ONBIw_BWYyq",
        "outputId": "aa54087d-a6ce-4145-80b3-20c893f3e000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1, 2.8, 4.7, 1.2],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [7.2, 3.6, 6.1, 2.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s5VFYlXLWYyq",
        "outputId": "4aee9182-9b20-4575-ee9a-884f9fcb3ba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ejZkXhOMWYyq",
        "outputId": "72ef4aa3-1f7f-480a-aa9c-ec0c64120328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAnU48VrWYyq"
      },
      "source": [
        "## Standardizing the Data\n",
        "\n",
        "Usually when using Neural Networks, you will get better performance when you standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n",
        "\n",
        "The scikit learn library also provides a nice function for this.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mB2o-n2VWYyq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1d8bvObwWYyq"
      },
      "outputs": [],
      "source": [
        "scaler_object = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CfapRpxNWYyq",
        "outputId": "94dc008d-d559-4d44-a754-2bda8e4dd13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "scaler_object.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hLzMCOSMWYyq"
      },
      "outputs": [],
      "source": [
        "scaled_X_train = scaler_object.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DP-uNvrPWYyq"
      },
      "outputs": [],
      "source": [
        "scaled_X_test = scaler_object.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fa6IHa0WYyq"
      },
      "source": [
        "Ok, now we have the data scaled!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i65XLtIQWYyr",
        "outputId": "f18c9661-03df-440d-e052-723a0e08f41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.7"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "X_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "y_3HScWeWYyr",
        "outputId": "9d72d7fd-13fb-440d-e808-72489dab7ef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "scaled_X_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5QP-PWnQWYyr",
        "outputId": "bd44b869-2831-441b-e6f5-326473be0b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7, 2.9, 4.2, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [7.1, 3. , 5.9, 2.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DG3eXy7KWYyr",
        "outputId": "fdd3c1b1-635f-44d8-dd45-1d85d1770917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "scaled_X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajrUxLDXWYyr"
      },
      "source": [
        "## Building the Network with Keras\n",
        "\n",
        "Let's build a simple neural network!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GHHIHqi9WYyr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sv0JrlqhWYyr",
        "outputId": "fecd9250-4b25-4d58-eb49-69958a37e220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ch8uPiJ4WYyr",
        "outputId": "af0daaeb-afcb-42f0-a352-758d755f3800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                                 \u001b[38;5;34m40\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                                 \u001b[38;5;34m72\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                                 \u001b[38;5;34m27\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139\u001b[0m (556.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139</span> (556.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139\u001b[0m (556.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139</span> (556.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk7ntWF8WYyr"
      },
      "source": [
        "## Fit (Train) the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Sg3pvJ88WYyr",
        "outputId": "19941865-9d07-4d81-9c02-41ee33f664d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "4/4 - 1s - 334ms/step - accuracy: 0.3400 - loss: 1.0509\n",
            "Epoch 2/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.3400 - loss: 1.0431\n",
            "Epoch 3/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3400 - loss: 1.0367\n",
            "Epoch 4/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3400 - loss: 1.0303\n",
            "Epoch 5/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.3400 - loss: 1.0246\n",
            "Epoch 6/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3400 - loss: 1.0189\n",
            "Epoch 7/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3400 - loss: 1.0128\n",
            "Epoch 8/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3400 - loss: 1.0074\n",
            "Epoch 9/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.3400 - loss: 1.0012\n",
            "Epoch 10/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.3400 - loss: 0.9949\n",
            "Epoch 11/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3500 - loss: 0.9892\n",
            "Epoch 12/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3600 - loss: 0.9831\n",
            "Epoch 13/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3700 - loss: 0.9776\n",
            "Epoch 14/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3800 - loss: 0.9720\n",
            "Epoch 15/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3800 - loss: 0.9664\n",
            "Epoch 16/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3900 - loss: 0.9611\n",
            "Epoch 17/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.3900 - loss: 0.9553\n",
            "Epoch 18/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.4100 - loss: 0.9499\n",
            "Epoch 19/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.4400 - loss: 0.9444\n",
            "Epoch 20/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.4500 - loss: 0.9393\n",
            "Epoch 21/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.4700 - loss: 0.9344\n",
            "Epoch 22/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.5000 - loss: 0.9293\n",
            "Epoch 23/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.5100 - loss: 0.9241\n",
            "Epoch 24/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.5200 - loss: 0.9189\n",
            "Epoch 25/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.5200 - loss: 0.9135\n",
            "Epoch 26/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.5300 - loss: 0.9082\n",
            "Epoch 27/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.5600 - loss: 0.9025\n",
            "Epoch 28/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.5600 - loss: 0.8968\n",
            "Epoch 29/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.5700 - loss: 0.8909\n",
            "Epoch 30/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.6100 - loss: 0.8846\n",
            "Epoch 31/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.6100 - loss: 0.8782\n",
            "Epoch 32/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6200 - loss: 0.8713\n",
            "Epoch 33/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.6200 - loss: 0.8648\n",
            "Epoch 34/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.6400 - loss: 0.8586\n",
            "Epoch 35/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.6400 - loss: 0.8516\n",
            "Epoch 36/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6600 - loss: 0.8448\n",
            "Epoch 37/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.6600 - loss: 0.8382\n",
            "Epoch 38/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.8312\n",
            "Epoch 39/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.6800 - loss: 0.8245\n",
            "Epoch 40/250\n",
            "4/4 - 0s - 31ms/step - accuracy: 0.6800 - loss: 0.8172\n",
            "Epoch 41/250\n",
            "4/4 - 0s - 35ms/step - accuracy: 0.6700 - loss: 0.8102\n",
            "Epoch 42/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6700 - loss: 0.8028\n",
            "Epoch 43/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.7956\n",
            "Epoch 44/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6800 - loss: 0.7884\n",
            "Epoch 45/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.7813\n",
            "Epoch 46/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.7741\n",
            "Epoch 47/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.6800 - loss: 0.7669\n",
            "Epoch 48/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.6800 - loss: 0.7595\n",
            "Epoch 49/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6800 - loss: 0.7518\n",
            "Epoch 50/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.7443\n",
            "Epoch 51/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.6800 - loss: 0.7364\n",
            "Epoch 52/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6800 - loss: 0.7278\n",
            "Epoch 53/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.7195\n",
            "Epoch 54/250\n",
            "4/4 - 0s - 17ms/step - accuracy: 0.6800 - loss: 0.7109\n",
            "Epoch 55/250\n",
            "4/4 - 0s - 17ms/step - accuracy: 0.6800 - loss: 0.7016\n",
            "Epoch 56/250\n",
            "4/4 - 0s - 17ms/step - accuracy: 0.6800 - loss: 0.6933\n",
            "Epoch 57/250\n",
            "4/4 - 0s - 18ms/step - accuracy: 0.6800 - loss: 0.6847\n",
            "Epoch 58/250\n",
            "4/4 - 0s - 18ms/step - accuracy: 0.6800 - loss: 0.6763\n",
            "Epoch 59/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.6800 - loss: 0.6681\n",
            "Epoch 60/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.6599\n",
            "Epoch 61/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.6800 - loss: 0.6517\n",
            "Epoch 62/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.6800 - loss: 0.6439\n",
            "Epoch 63/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6800 - loss: 0.6360\n",
            "Epoch 64/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.6800 - loss: 0.6276\n",
            "Epoch 65/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.6800 - loss: 0.6199\n",
            "Epoch 66/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.6800 - loss: 0.6122\n",
            "Epoch 67/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6900 - loss: 0.6043\n",
            "Epoch 68/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.6900 - loss: 0.5964\n",
            "Epoch 69/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.6900 - loss: 0.5891\n",
            "Epoch 70/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.6900 - loss: 0.5813\n",
            "Epoch 71/250\n",
            "4/4 - 0s - 34ms/step - accuracy: 0.6900 - loss: 0.5741\n",
            "Epoch 72/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.6900 - loss: 0.5672\n",
            "Epoch 73/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7200 - loss: 0.5603\n",
            "Epoch 74/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.7300 - loss: 0.5539\n",
            "Epoch 75/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.7300 - loss: 0.5480\n",
            "Epoch 76/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.7300 - loss: 0.5418\n",
            "Epoch 77/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7300 - loss: 0.5355\n",
            "Epoch 78/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.7300 - loss: 0.5298\n",
            "Epoch 79/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.7200 - loss: 0.5247\n",
            "Epoch 80/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7200 - loss: 0.5189\n",
            "Epoch 81/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.7200 - loss: 0.5136\n",
            "Epoch 82/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.7300 - loss: 0.5086\n",
            "Epoch 83/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.7300 - loss: 0.5036\n",
            "Epoch 84/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.7300 - loss: 0.4989\n",
            "Epoch 85/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.7400 - loss: 0.4945\n",
            "Epoch 86/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.7600 - loss: 0.4902\n",
            "Epoch 87/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7600 - loss: 0.4859\n",
            "Epoch 88/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7700 - loss: 0.4819\n",
            "Epoch 89/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7700 - loss: 0.4780\n",
            "Epoch 90/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.7700 - loss: 0.4741\n",
            "Epoch 91/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8100 - loss: 0.4711\n",
            "Epoch 92/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8200 - loss: 0.4668\n",
            "Epoch 93/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.8200 - loss: 0.4634\n",
            "Epoch 94/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8200 - loss: 0.4603\n",
            "Epoch 95/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8100 - loss: 0.4570\n",
            "Epoch 96/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8100 - loss: 0.4538\n",
            "Epoch 97/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8200 - loss: 0.4502\n",
            "Epoch 98/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8200 - loss: 0.4471\n",
            "Epoch 99/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8300 - loss: 0.4439\n",
            "Epoch 100/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8300 - loss: 0.4408\n",
            "Epoch 101/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8300 - loss: 0.4379\n",
            "Epoch 102/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.8400 - loss: 0.4350\n",
            "Epoch 103/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.8600 - loss: 0.4323\n",
            "Epoch 104/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8600 - loss: 0.4295\n",
            "Epoch 105/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8600 - loss: 0.4268\n",
            "Epoch 106/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.8600 - loss: 0.4241\n",
            "Epoch 107/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8600 - loss: 0.4214\n",
            "Epoch 108/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8600 - loss: 0.4190\n",
            "Epoch 109/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.8800 - loss: 0.4161\n",
            "Epoch 110/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.8600 - loss: 0.4133\n",
            "Epoch 111/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.8600 - loss: 0.4105\n",
            "Epoch 112/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8800 - loss: 0.4078\n",
            "Epoch 113/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8900 - loss: 0.4051\n",
            "Epoch 114/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.8900 - loss: 0.4023\n",
            "Epoch 115/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.8900 - loss: 0.3995\n",
            "Epoch 116/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8900 - loss: 0.3965\n",
            "Epoch 117/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8900 - loss: 0.3936\n",
            "Epoch 118/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9000 - loss: 0.3908\n",
            "Epoch 119/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8900 - loss: 0.3881\n",
            "Epoch 120/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.8700 - loss: 0.3868\n",
            "Epoch 121/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8600 - loss: 0.3848\n",
            "Epoch 122/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.8600 - loss: 0.3825\n",
            "Epoch 123/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.8800 - loss: 0.3784\n",
            "Epoch 124/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9100 - loss: 0.3741\n",
            "Epoch 125/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3709\n",
            "Epoch 126/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9200 - loss: 0.3687\n",
            "Epoch 127/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9200 - loss: 0.3659\n",
            "Epoch 128/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9200 - loss: 0.3626\n",
            "Epoch 129/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9200 - loss: 0.3598\n",
            "Epoch 130/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9200 - loss: 0.3568\n",
            "Epoch 131/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9200 - loss: 0.3538\n",
            "Epoch 132/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.9300 - loss: 0.3517\n",
            "Epoch 133/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3491\n",
            "Epoch 134/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9200 - loss: 0.3469\n",
            "Epoch 135/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3443\n",
            "Epoch 136/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3416\n",
            "Epoch 137/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9300 - loss: 0.3389\n",
            "Epoch 138/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3360\n",
            "Epoch 139/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.3343\n",
            "Epoch 140/250\n",
            "4/4 - 0s - 7ms/step - accuracy: 0.9300 - loss: 0.3305\n",
            "Epoch 141/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9300 - loss: 0.3295\n",
            "Epoch 142/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.3270\n",
            "Epoch 143/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.3250\n",
            "Epoch 144/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.3231\n",
            "Epoch 145/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.3208\n",
            "Epoch 146/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.3184\n",
            "Epoch 147/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.3165\n",
            "Epoch 148/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.9500 - loss: 0.3149\n",
            "Epoch 149/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9500 - loss: 0.3125\n",
            "Epoch 150/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.3096\n",
            "Epoch 151/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.3071\n",
            "Epoch 152/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.3048\n",
            "Epoch 153/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9400 - loss: 0.3027\n",
            "Epoch 154/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.3010\n",
            "Epoch 155/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2988\n",
            "Epoch 156/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2966\n",
            "Epoch 157/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2943\n",
            "Epoch 158/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2928\n",
            "Epoch 159/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.2905\n",
            "Epoch 160/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2884\n",
            "Epoch 161/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2874\n",
            "Epoch 162/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9500 - loss: 0.2863\n",
            "Epoch 163/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2857\n",
            "Epoch 164/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.2845\n",
            "Epoch 165/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2817\n",
            "Epoch 166/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2790\n",
            "Epoch 167/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2777\n",
            "Epoch 168/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2770\n",
            "Epoch 169/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2741\n",
            "Epoch 170/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2709\n",
            "Epoch 171/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9500 - loss: 0.2679\n",
            "Epoch 172/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2664\n",
            "Epoch 173/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9500 - loss: 0.2649\n",
            "Epoch 174/250\n",
            "4/4 - 0s - 16ms/step - accuracy: 0.9500 - loss: 0.2635\n",
            "Epoch 175/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.9500 - loss: 0.2621\n",
            "Epoch 176/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9500 - loss: 0.2601\n",
            "Epoch 177/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2579\n",
            "Epoch 178/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2561\n",
            "Epoch 179/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2544\n",
            "Epoch 180/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2534\n",
            "Epoch 181/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2521\n",
            "Epoch 182/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2497\n",
            "Epoch 183/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2477\n",
            "Epoch 184/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9600 - loss: 0.2469\n",
            "Epoch 185/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9400 - loss: 0.2465\n",
            "Epoch 186/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9300 - loss: 0.2469\n",
            "Epoch 187/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9300 - loss: 0.2478\n",
            "Epoch 188/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9300 - loss: 0.2458\n",
            "Epoch 189/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9400 - loss: 0.2413\n",
            "Epoch 190/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2373\n",
            "Epoch 191/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2355\n",
            "Epoch 192/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9600 - loss: 0.2340\n",
            "Epoch 193/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2333\n",
            "Epoch 194/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.9400 - loss: 0.2326\n",
            "Epoch 195/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9400 - loss: 0.2319\n",
            "Epoch 196/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9400 - loss: 0.2297\n",
            "Epoch 197/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9600 - loss: 0.2269\n",
            "Epoch 198/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2249\n",
            "Epoch 199/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2250\n",
            "Epoch 200/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2271\n",
            "Epoch 201/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2257\n",
            "Epoch 202/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2222\n",
            "Epoch 203/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2182\n",
            "Epoch 204/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.2168\n",
            "Epoch 205/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9500 - loss: 0.2166\n",
            "Epoch 206/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2160\n",
            "Epoch 207/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2147\n",
            "Epoch 208/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2144\n",
            "Epoch 209/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9400 - loss: 0.2130\n",
            "Epoch 210/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.2110\n",
            "Epoch 211/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9500 - loss: 0.2092\n",
            "Epoch 212/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.2076\n",
            "Epoch 213/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9600 - loss: 0.2063\n",
            "Epoch 214/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9600 - loss: 0.2049\n",
            "Epoch 215/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9600 - loss: 0.2036\n",
            "Epoch 216/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9500 - loss: 0.2026\n",
            "Epoch 217/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9400 - loss: 0.2026\n",
            "Epoch 218/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9400 - loss: 0.2026\n",
            "Epoch 219/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.2013\n",
            "Epoch 220/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9400 - loss: 0.1989\n",
            "Epoch 221/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.1964\n",
            "Epoch 222/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9700 - loss: 0.1954\n",
            "Epoch 223/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9600 - loss: 0.1950\n",
            "Epoch 224/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.1947\n",
            "Epoch 225/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.1935\n",
            "Epoch 226/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1921\n",
            "Epoch 227/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9700 - loss: 0.1907\n",
            "Epoch 228/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1895\n",
            "Epoch 229/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1881\n",
            "Epoch 230/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9700 - loss: 0.1871\n",
            "Epoch 231/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.1861\n",
            "Epoch 232/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.1852\n",
            "Epoch 233/250\n",
            "4/4 - 0s - 15ms/step - accuracy: 0.9700 - loss: 0.1841\n",
            "Epoch 234/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9600 - loss: 0.1835\n",
            "Epoch 235/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.1823\n",
            "Epoch 236/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1808\n",
            "Epoch 237/250\n",
            "4/4 - 0s - 10ms/step - accuracy: 0.9700 - loss: 0.1806\n",
            "Epoch 238/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9700 - loss: 0.1808\n",
            "Epoch 239/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9700 - loss: 0.1801\n",
            "Epoch 240/250\n",
            "4/4 - 0s - 12ms/step - accuracy: 0.9600 - loss: 0.1769\n",
            "Epoch 241/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9500 - loss: 0.1769\n",
            "Epoch 242/250\n",
            "4/4 - 0s - 13ms/step - accuracy: 0.9500 - loss: 0.1766\n",
            "Epoch 243/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9400 - loss: 0.1760\n",
            "Epoch 244/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9500 - loss: 0.1747\n",
            "Epoch 245/250\n",
            "4/4 - 0s - 14ms/step - accuracy: 0.9600 - loss: 0.1729\n",
            "Epoch 246/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1720\n",
            "Epoch 247/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1716\n",
            "Epoch 248/250\n",
            "4/4 - 0s - 8ms/step - accuracy: 0.9700 - loss: 0.1705\n",
            "Epoch 249/250\n",
            "4/4 - 0s - 11ms/step - accuracy: 0.9700 - loss: 0.1695\n",
            "Epoch 250/250\n",
            "4/4 - 0s - 9ms/step - accuracy: 0.9700 - loss: 0.1688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c626b2bb4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Play around with number of epochs as well!\n",
        "model.fit(scaled_X_train,y_train,epochs=250, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fDj1P3WYys"
      },
      "source": [
        "## Predicting New Unseen Data\n",
        "\n",
        "Let's see how we did by predicting on **new data**. Remember, our model has **never** seen the test data that we scaled previously! This process is the exact same process you would use on totally brand new data. For example , a brand new bank note that you just analyzed ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VxCrIE4DWYys",
        "outputId": "31ea61d0-7b54-44ad-8710-a3c385dff8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52941176,  0.36363636,  0.64285714,  0.45833333],\n",
              "       [ 0.41176471,  0.81818182,  0.10714286,  0.08333333],\n",
              "       [ 1.        ,  0.27272727,  1.03571429,  0.91666667],\n",
              "       [ 0.5       ,  0.40909091,  0.60714286,  0.58333333],\n",
              "       [ 0.73529412,  0.36363636,  0.66071429,  0.54166667],\n",
              "       [ 0.32352941,  0.63636364,  0.07142857,  0.125     ],\n",
              "       [ 0.38235294,  0.40909091,  0.44642857,  0.5       ],\n",
              "       [ 0.76470588,  0.5       ,  0.71428571,  0.91666667],\n",
              "       [ 0.55882353,  0.09090909,  0.60714286,  0.58333333],\n",
              "       [ 0.44117647,  0.31818182,  0.5       ,  0.45833333],\n",
              "       [ 0.64705882,  0.54545455,  0.71428571,  0.79166667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.        ],\n",
              "       [ 0.35294118,  0.68181818,  0.03571429,  0.04166667],\n",
              "       [ 0.17647059,  0.5       ,  0.07142857,  0.        ],\n",
              "       [ 0.23529412,  0.81818182,  0.07142857,  0.08333333],\n",
              "       [ 0.58823529,  0.59090909,  0.64285714,  0.625     ],\n",
              "       [ 0.64705882,  0.45454545,  0.83928571,  0.875     ],\n",
              "       [ 0.38235294,  0.22727273,  0.5       ,  0.41666667],\n",
              "       [ 0.41176471,  0.36363636,  0.60714286,  0.5       ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.875     ],\n",
              "       [ 0.11764706,  0.54545455,  0.08928571,  0.04166667],\n",
              "       [ 0.52941176,  0.45454545,  0.67857143,  0.70833333],\n",
              "       [ 0.20588235,  0.63636364,  0.08928571,  0.125     ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.83333333],\n",
              "       [ 1.05882353,  0.81818182,  0.94642857,  0.79166667],\n",
              "       [ 0.70588235,  0.45454545,  0.73214286,  0.91666667],\n",
              "       [ 0.70588235,  0.22727273,  0.83928571,  0.70833333],\n",
              "       [ 0.73529412,  0.54545455,  0.85714286,  0.91666667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.08333333],\n",
              "       [ 0.14705882,  0.5       ,  0.08928571,  0.04166667],\n",
              "       [ 0.08823529,  0.72727273, -0.01785714,  0.04166667],\n",
              "       [ 0.41176471,  1.09090909,  0.07142857,  0.125     ],\n",
              "       [ 0.70588235,  0.5       ,  0.58928571,  0.54166667],\n",
              "       [ 0.14705882,  0.63636364,  0.08928571,  0.04166667],\n",
              "       [ 0.02941176,  0.54545455,  0.03571429,  0.04166667],\n",
              "       [ 0.58823529,  0.22727273,  0.69642857,  0.75      ],\n",
              "       [ 0.61764706,  0.54545455,  0.60714286,  0.58333333],\n",
              "       [ 0.26470588,  0.68181818,  0.07142857,  0.04166667],\n",
              "       [ 0.20588235,  0.72727273,  0.05357143,  0.04166667],\n",
              "       [ 0.26470588,  0.95454545,  0.07142857,  0.        ],\n",
              "       [ 0.44117647,  0.31818182,  0.71428571,  0.75      ],\n",
              "       [ 0.5       ,  0.63636364,  0.60714286,  0.625     ],\n",
              "       [ 0.70588235,  0.5       ,  0.64285714,  0.58333333],\n",
              "       [ 0.32352941,  0.86363636,  0.03571429,  0.125     ],\n",
              "       [ 0.32352941,  0.77272727,  0.07142857,  0.04166667],\n",
              "       [ 0.35294118,  0.18181818,  0.46428571,  0.375     ],\n",
              "       [ 0.58823529,  0.36363636,  0.71428571,  0.58333333],\n",
              "       [ 0.61764706,  0.5       ,  0.78571429,  0.70833333],\n",
              "       [ 0.67647059,  0.45454545,  0.58928571,  0.54166667],\n",
              "       [ 0.85294118,  0.72727273,  0.89285714,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "scaled_X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hRSYBJyFWYys",
        "outputId": "cebb4f28-dfe4-4981-d0f8-9fb298610098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.4804270e-03, 8.3541274e-01, 1.6210675e-01],\n",
              "       [9.9483818e-01, 5.0642765e-03, 9.7478893e-05],\n",
              "       [2.2457295e-08, 8.5121877e-03, 9.9148780e-01],\n",
              "       [9.8729774e-04, 7.0091134e-01, 2.9810131e-01],\n",
              "       [2.7630074e-04, 5.7522053e-01, 4.2450309e-01],\n",
              "       [9.8732936e-01, 1.2356998e-02, 3.1367148e-04],\n",
              "       [6.4468011e-03, 9.1482800e-01, 7.8725137e-02],\n",
              "       [1.1188587e-06, 5.4846261e-02, 9.4515246e-01],\n",
              "       [1.8755958e-04, 2.8470200e-01, 7.1511036e-01],\n",
              "       [5.1213382e-03, 8.8396144e-01, 1.1091731e-01],\n",
              "       [2.7784941e-05, 2.4278644e-01, 7.5718570e-01],\n",
              "       [9.9353421e-01, 6.1890706e-03, 2.7664838e-04],\n",
              "       [9.9534178e-01, 4.5519331e-03, 1.0631938e-04],\n",
              "       [9.9429387e-01, 5.4811812e-03, 2.2502414e-04],\n",
              "       [9.9780393e-01, 2.1343490e-03, 6.1578525e-05],\n",
              "       [5.6038942e-04, 7.4431700e-01, 2.5512254e-01],\n",
              "       [2.2764505e-06, 5.6425586e-02, 9.4357210e-01],\n",
              "       [8.7447250e-03, 8.8727409e-01, 1.0398126e-01],\n",
              "       [3.5103243e-03, 8.3277541e-01, 1.6371427e-01],\n",
              "       [1.9111612e-06, 4.3072525e-02, 9.5692545e-01],\n",
              "       [9.9455947e-01, 5.2059898e-03, 2.3437536e-04],\n",
              "       [1.5956226e-04, 3.9752850e-01, 6.0231185e-01],\n",
              "       [9.9200630e-01, 7.7310372e-03, 2.6260203e-04],\n",
              "       [3.9422143e-06, 6.2993824e-02, 9.3700218e-01],\n",
              "       [2.3252078e-06, 1.9152996e-01, 8.0846763e-01],\n",
              "       [1.1995184e-06, 4.7258630e-02, 9.5274013e-01],\n",
              "       [6.3187176e-06, 7.4515581e-02, 9.2547798e-01],\n",
              "       [9.2034202e-07, 4.6919256e-02, 9.5307982e-01],\n",
              "       [9.8863155e-01, 1.0897340e-02, 4.7102018e-04],\n",
              "       [9.9247354e-01, 7.2117820e-03, 3.1464969e-04],\n",
              "       [9.9822044e-01, 1.7199295e-03, 5.9620503e-05],\n",
              "       [9.9866343e-01, 1.3161724e-03, 2.0391730e-05],\n",
              "       [6.0960493e-04, 7.8669369e-01, 2.1269672e-01],\n",
              "       [9.9645633e-01, 3.4064376e-03, 1.3719749e-04],\n",
              "       [9.9528897e-01, 4.4973334e-03, 2.1362718e-04],\n",
              "       [1.4829116e-05, 1.0134546e-01, 8.9863968e-01],\n",
              "       [7.1141281e-04, 7.8297782e-01, 2.1631078e-01],\n",
              "       [9.9623883e-01, 3.6522434e-03, 1.0887250e-04],\n",
              "       [9.9780726e-01, 2.1224979e-03, 7.0320020e-05],\n",
              "       [9.9934179e-01, 6.4206048e-04, 1.6057300e-05],\n",
              "       [6.8056856e-05, 1.9266883e-01, 8.0726314e-01],\n",
              "       [1.1456117e-03, 8.3457065e-01, 1.6428371e-01],\n",
              "       [3.3636767e-04, 6.7497051e-01, 3.2469308e-01],\n",
              "       [9.9704885e-01, 2.8892318e-03, 6.1928178e-05],\n",
              "       [9.9715000e-01, 2.7819020e-03, 6.8015281e-05],\n",
              "       [1.5358866e-02, 8.9694041e-01, 8.7700732e-02],\n",
              "       [3.5041277e-04, 5.1656914e-01, 4.8308057e-01],\n",
              "       [7.1151750e-05, 3.2411802e-01, 6.7581081e-01],\n",
              "       [6.4462307e-04, 7.5747234e-01, 2.4188295e-01],\n",
              "       [2.3378068e-07, 3.6807165e-02, 9.6319258e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# before tf 2.6\n",
        "# prediction_classes = model.predict_classes (scaled_X_test)\n",
        "\n",
        "#since tf 2.6 and later\n",
        "predictions = model.predict(scaled_X_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rcIJXOLDWYys",
        "outputId": "d30b53ba-d449-4c3d-9a3b-b4b88d6bdbcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "prediction_classes=np.argmax(predictions,axis=1)\n",
        "prediction_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbn9GpmlWYys"
      },
      "source": [
        "# Evaluating Model Performance\n",
        "\n",
        "So how well did we do? How do we actually measure \"well\". Is 95% accuracy good enough? It all depends on the situation. Also we need to take into account things like recall and precision. Make sure to watch the video discussion on classification evaluation before running this code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IdeBCgDiWYys",
        "outputId": "dedf627d-f154-4b34-b171-e411b39869b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'compile_metrics']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7S9kOJiKWYys",
        "outputId": "3e31ea34-7a13-41dc-b4cf-6f8a93e056f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9629 - loss: 0.1492  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15149538218975067, 0.9599999785423279]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.evaluate(x=scaled_X_test,y=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "g-O6dKX4WYys"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qjV70Ky8WYys",
        "outputId": "387a9f84-1270-4a2d-ec6e-c5d6f181e3c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ],
      "source": [
        "predictions=model.predict(scaled_X_test)\n",
        "predictions_classes=np.argmax(predictions,axis=1)\n",
        "\n",
        "#predictions = model.predict_classes(scaled_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XG1rViCWWYys",
        "outputId": "54fb7388-b75c-4fb9-bf0d-3c1805ac0f10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "predictions_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4Baxio-nWYys",
        "outputId": "e3901472-c49b-48f5-eb72-fde3bad43032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "y_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xWNmb-OdWYys",
        "outputId": "6e22cf23-49e8-41d7-a824-a83bc01da516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  0],\n",
              "       [ 0, 14,  1],\n",
              "       [ 0,  1, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "confusion_matrix(y_test.argmax(axis=1),predictions_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8ikUIB3XWYys",
        "outputId": "2e895526-773d-48fa-e66d-6e00cf6f9d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.93      0.93      0.93        15\n",
            "           2       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.96        50\n",
            "   macro avg       0.96      0.96      0.96        50\n",
            "weighted avg       0.96      0.96      0.96        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test.argmax(axis=1),predictions_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhnhLNN2WYys"
      },
      "source": [
        "## Saving and Loading Models\n",
        "\n",
        "Now that we have a model trained, let's see how we can save and load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "BQn5JWPhWYyt"
      },
      "outputs": [],
      "source": [
        "model.save('myfirstmodel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OUbXrkpGWYyt"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8jb44yKmWYyt",
        "outputId": "8d2a3182-9174-4eab-8468-d73d9a8cfa02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "newmodel = load_model('myfirstmodel.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Y3E5O5w5WYyt",
        "outputId": "ac9165be-9661-4ba2-cb52-963cc973dd63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2,\n",
              "       1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1,\n",
              "       1, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# before tf 2.6\n",
        "# newmodel.predict_classes(X_test)\n",
        "\n",
        "#since tf 2.6 and later\n",
        "np.argmax(newmodel.predict(X_test), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8p1ImhvWYyt"
      },
      "source": [
        "Great job! You now know how to preprocess data, train a neural network, and evaluate its classification performance!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcQDiKsPWYyt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}